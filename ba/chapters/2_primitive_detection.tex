\chapter{Primitive Detection Algorithms}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\linewidth]{images/primitive_detection}
    \caption{Process of detecting primitives}
    \label{fig:primitive_detection}
\end{figure}
Primitive detection is a well-established area in computer vision that aims to detect simple geometric shapes
like planes, spheres, cylinders, or cones a given input data.
These methods are model-fitting algorithms that identify the most likely model that fits a subset of the input data.
The result of these algorithms is a set of parameters that describe the detected shape.
These shapes are an abstraction of the input data, offering a simplified compact representation of the data,
allowing for higher performance and the ability to perform higher-level tasks such as object recognition or scene reconstruction.
The input data representation varies by algorithm, with the most common types being:
\begin{itemize}
    \item \textbf{Point Clouds:} A set of 3D points in space representing the sampled surface of the real-world
    \item \textbf{Depth Images:} A 2D image where each pixel represents the distance to the camera, typically obtained from depth sensors
    \item \textbf{Image Sequences:} A sequence of 2D images from different viewpoints that are typically first convert to a point cloud or depth image for further processing, further discussed in section~\ref{sec:technical-background-depth-from-motion}
    \item \textbf{Meshes:} A polygonal representation of surfaces, consisting of vertices, edges, and faces, typically generated from surface reconstruction algorithms.
    Not further considered in this thesis.
    For an explanation of meshes, see section~\ref{subsec:polygon-meshes}.~\cite{kaiser_survey_2019}
\end{itemize}

This chapter provides an overview of the most common primitive detection algorithms by categorizing them based on their underlying methodology.
The chapter then compares the two most widely used base methodologies,
the Hough Transform and the Random Sample Consensus (RANSAC) algorithm.


\section{Categorization}
\citeauthor{kaiser_survey_2019}~\cite{kaiser_survey_2019} reviewed over 70 detection algorithms, evaluating them based on their input/output data types,
underlying methodology, supported primitive types, context of application and provides a rating for multiple criteria.
The authors categorize the underlying methodology of the algorithms into three categories:
\begin{itemize}
    \item \textbf{Stochastic:} algorithms that use random sampling to detect primitives, such as RANSAC
    \item \textbf{Parameter Space:} algorithms that use a parameter space to detect primitives, such as the Hough Transform
    \item \textbf{Other techniques}, for example primitive-driven region growing
\end{itemize}

The following sections provide an overview of the most common algorithms in each category.

\subsection{RANSAC (Stochastic)}
The Random Sample Consensus (RANSAC) algorithm is a widely used stochastic model parameter estimation
algorithm first introduced in~\citeyear{fischler_random_1981}
by~\citeauthor{fischler_random_1981}~\cite{fischler_random_1981}.
"The basic principle of the algorithm is to try many possible randomized models that could fit
the data and evaluate how good this model is in order to find a consensus,
i.e.\ an agreement of most of the data samples."~\parencite{kaiser_survey_2019}

For a given shape that requires $n$ points to be defined, RANSAC follows the following steps to detect the shape
in a set of data points $P$~\parencite{fischler_random_1981}:
\begin{enumerate}
    \item Randomly select a subset $S1$ of $n$ data points from $P$
    \item Fit the model $M1$ to the selected points
    \item Determine if the subset of inliers $S1^*$ of $P$ that fit the model $M1$ within a predefined tolerance, this is called the consensus set
    \item If size of the consensus set $|S1^*|$ is greater than a predefined threshold $t$, re-fit the model to $S1^*$, resulting in new model $M1^*$
    \item If size of the consensus set $|S1^*|$ is smaller than a predefined threshold $t$, repeat until a model with a consensus set of size $t$ is found or a predefined number of iterations is reached
\end{enumerate}

The algorithm has 3 main parameters that need to be set:
\begin{itemize}
    \item \textbf{Error tolernace:} the distance between a data point and the model under which the data point is considered an inlier
    \item \textbf{Threshold $t$:} the number of inliers required to consider a model valid
    \item \textbf{Number of iterations:} the number of times the algorithm will try to find a model with a consensus set of size $t$
\end{itemize}

\subsection{Hough Transform (Parameter Space)}
The Hough transform (HT) introduced in~\citeyear{hough_method_1962}~\parencite{hough_method_1962}
is an algorithm that was originally designed to detect lines in images,
but has since been generalized to detect more complex shapes like circles~\cite{ballard_generalizing_1981} and 3D shapes~\cite{woodford_demisting_2014}.

The HT works by creating a voting space based on parameters where similar shapes overlap\cite{kaiser_survey_2019}.
The following explanation of the HT is based on~\cite{shree_k_nayar_first_2021}.
Figure~\ref{fig:hough-transform} illustrates the concept of the Hough Transform for detecting lines.
On the left, the image space is shown, where 4 points are located on a line.
The right side shows the parameter space, where the axes represent the parameters of the line equation
\begin{equation}
    y = mx + c
\end{equation}
Each point in image space creates a line in parameter space, as there are an infinite number of lines that pass through a point.
All points on the line represent a valid parameterizations of the line.
When all points are plotted in parameter space, local maxima represent possible lines that fit the input data.
\begin{figure}[ht!]
    \centering
    \begin{subfigure}[t]{0.45\textwidth} % Adjusted from 0.4 to 0.45
        \centering
        \begin{tikzpicture}

            % Axes
            \draw[->] (0,0) -- (4,0) node[right] {$x$};
            \draw[->] (0,0) -- (0,4) node[above] {$y$};

            % Line
            \draw[dashed] (0.5,1) -- (4.5,4);

            % Points on the line y = 0.75x + 0.625
            \foreach \x in {1, 2, 3, 4} {
                \pgfmathsetmacro\y{0.75*\x + 0.625}
                \filldraw (\x,\y) circle (2pt);
            }

%        % Label for a point
%        \draw[->] (2,2.125) -- (2.5,2.5) node[above] {$(x_i, y_i)$};

            % Equation
            \node at (2.5,-0.5) {$y_i = mx_i + c$};

            % Title
%            \node at (2.5,5.5) {\textbf{Image Space}};


        \end{tikzpicture}
        %    source: szeliski_computer_nodate
        \caption{Image Space}
        \label{fig:ht-1}
    \end{subfigure}%
    \hspace{0.05\textwidth} % Added space between subfigures
    \begin{subfigure}[t]{0.45\textwidth} % Adjusted from 0.4 to 0.45
        \centering
        \begin{tikzpicture}
            % Draw axes
            \draw[->] (0,0) -- (4,0) node[right] {$m$};
            \draw[->] (0,0) -- (0,4) node[above] {$c$};
            % Define the point (m, c)
            \coordinate (mc) at (2.5,2.5);
            % Draw the point (m, c)
            \filldraw (mc) circle (2pt) node[right] {$(m,c)$};
            % Draw lines radiating from the point (m, c)
            \foreach \angle in {0, 15, 30, 45} {
                \draw[thick] (mc) -- ++(\angle-70:2);
                \draw[thick] (mc) -- ++(\angle-70+180:2);
            }
            % Add the equation below the graph
            \node at (2.5,-0.5) {$c = -mx_i + y_i$};
        \end{tikzpicture}

        \caption{Parameter Space}
    \end{subfigure}%
    \caption{Concept of Hough Transform illlustrated for the usage of detecting lines}
    \label{fig:hough-transform}
\end{figure}

The Hough Transform is implemented by discretizing the parameter space into uniform sections
using a two-dimensional array to store the votes for each parameter, called the accumulator~\parencite{duda_use_1972}.
Each data point contributes votes to the shapes it aligns with, indicating the likelihood of a specific shape being present in the input data.
By accumulating these votes, the parameters corresponding to the shape with the highest number of votes can be identified.
After all data points have voted, the parameters with the highest votes reveal the shape that most accurately fits the input data.

A problem that arises when using the Hough Transform using the standard parameterization of a line $y = mx + c$
is that the slope $m$ can be infinite for vertical lines, which would require the parameter space to be infinite.
To solve this problem, a parameterization using the angle from the x-axis $\theta$ and the distance from the origin $\rho$ is used:
\begin{equation}
    x \sin \theta + y \cos \theta = \rho = 0
\end{equation}
\begin{figure}[ht!]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \begin{tikzpicture}
            % Draw axes
            \draw[->] (-4,0) -- (0.25,0) node[right] {$x$};
            \draw[->] (0,-0.25) -- (0,3.5) node[above] {$y$};

            % Draw the line
            \draw[thick, shorten <=0.4cm, shorten >=0.4cm] (-3.5,-0.5) -- (0.5,3.5);

            % Draw the perpendicular distance
            \draw[dotted] (0,0) -- (-1.5,1.5);

            % Draw the dots
            \filldraw (-1.5,1.5) circle (2pt);
            \filldraw (-0.5,2.5) circle (2pt);

            % Mark the angle theta
            \draw[->] (-2.5,0) arc[start angle=0,end angle=65,radius=0.3];
            \node at (-2.3,0.2) {$\theta$};


            % Label rho
            \node at (-0.75,0.75) {$\rho$};


            % Label the equation
            \node at (-1.5,-0.5) {$x \sin \theta - y \cos \theta + \rho = 0$};
        \end{tikzpicture}


        %    source: szeliski_computer_nodate
        \caption{Image Space}
        \label{fig:ht-polar-1}
    \end{subfigure}%
    \hspace{0.05\textwidth} % Added space between subfigures
    \begin{subfigure}[t]{0.45\textwidth} % Adjusted from 0.4 to 0.45
        \begin{tikzpicture}
            % Draw axes
            \draw[->] (-1,0) -- (5,0) node[right] {$\theta$};
            \draw[->] (0,-1.5) -- (0,1.5) node[above] {$\rho$};

            % Draw the sinusoidal curve
            \draw[thick, domain=0:0.6666*6.28, samples=100] plot (\x, {sin(1.5*\x r)});
            \draw[thick, domain=0:0.6666*6.28, samples=100] plot (\x, {sin((1.5*\x + 1) r)});

            \filldraw (0.71386, 0.87) circle (2pt);
            \filldraw (2.80826, -0.87) circle (2pt);

            % Label the equation
            \node at (3,-1.5) {$x \sin \theta - y \cos \theta + \rho = 0$};
        \end{tikzpicture}

        \caption{Parameter Space}
        \label{fig:ht-polar-2}
    \end{subfigure}%
    \caption{Hough Transform using polar coordinates}
    \label{fig:hough-transform-polar}
\end{figure}
This parameterization allows for the representation of all lines, including ones that are vertical,
as the angle $\theta$ can be any value between $0$ and $\pi$; the distance $\rho$ between $0$ and the size of the image space.
This also decreases the size of the accumulator array.
To detect lines using this parameterization, the same voting process as described above is used.


\subsection{Primitive-driven Region Growing}
TODO


\section{Choosing an algorithm: Hough Transform vs RANSAC}\label{sec:choosing-an-algorithm}

\cite{kaiser_survey_2019} lists over 70 detection algorithms, many of which are specialized for specific application contexts
like indoor scenes, outdoor scenes, urban buildings or individual objects.
As this thesis aims to develop a general end to end implementation for detecting and rendering primitives in AR,
algorithms that are widely used and applicable to a wide range of applications will be considered.
Both the Hough Transform and the Random Sample Consensus (RANSAC) algorithm stand out as the
most widely used methodologies in the field of primitive detection~\parencite{schnabel_efficient_2007}.
This section provides a comparison of these two methodologies and a decision on which algorithm to use for the implementation.

In general, the performance of both algorithms varies based on the context of the application.
With optimizations, both algorithms are suitable for a wide range of applications, but
the Hough Transform is more computationally expensive than RANSAC~\parencite{kaiser_survey_2019}.
\cite{tarsha-kurdi_hough-transform_2007} found that its processing time is negligible in comparison to the Hough Transform.
RANSAC is also more robust to noise and outliers~\parencite{kaiser_survey_2019}.
It is also simpler and therefore easier to extend and adapt to different contexts~\parencite{tarsha-kurdi_hough-transform_2007, kaiser_survey_2019}.
The main drawback of RANSAC is that results are not repeatable, as the algorithm is based on random sampling~\parencite{kaiser_survey_2019}.


For a concrete example,~\cite{tarsha-kurdi_hough-transform_2007} analyzed the application of detecting building
roofs as planes in 3D Lidar scans of cityscapes, and found that by default both RANSAC and Hough-Transform yield similar,
insufficient results for their use-case.
“That can be explained by the use of a pure mathematical principle,
without taking into account the particularity of the building Lidar data. […] That is why
[they] may detect a set of points which represents several roof planes or which belongs to several planes.”
They also had difficulties to determine the parameters of Hough Transform,
as the optimal values vary based on the characteristics of the point cloud.
Motivated by RANSACS rapidity they investigated extending the RANSAC algorithm and with their improvements
found that it produces satisfying results.

In the end, both the Hough Transform and RANSAC are suitable algorithms for detecting primitives.
However, the Hough Transform is more computationally expensive, harder to tune for specific contexts and less robust to noise and outliers.
RANSAC also has a publicly available reference implementation in C\texttt{++} by~\parencite{schnabel_efficient_2007},
which is e.g.\ used in the open source tool CloudCompare~\parencite{daniel_girardeau-montaut_cloudcompare_nodate} and can therefore be
easily tested on ones own pointclouds without the need to write custom code, useful for evaluation, as can later be seen in chapter~\ref{ch:evaluation}.

Due to these reasons, the Random Sample Consensus (RANSAC) algorithm will be used for the implementation of the primitive detection in this thesis.
