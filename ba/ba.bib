
@article{kaiser_survey_2019,
	title = {A {Survey} of {Simple} {Geometric} {Primitives} {Detection} {Methods} for {Captured} {3D} {Data}},
	volume = {38},
	issn = {0167-7055, 1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13451},
	doi = {10.1111/cgf.13451},
	abstract = {The amount of captured 3D data is continuously increasing, with the democratization of consumer depth cameras, the development of modern multi-view stereo capture setups and the rise of single-view 3D capture based on machine learning. The analysis and representation of this ever growing volume of 3D data, often corrupted with acquisition noise and reconstruction artefacts, is a serious challenge at the frontier between computer graphics and computer vision. To that end, segmentation and optimization are crucial analysis components of the shape abstraction process, which can themselves be greatly simpliﬁed when performed on lightened geometric formats. In this survey, we review the algorithms which extract simple geometric primitives from raw dense 3D data. After giving an introduction to these techniques, from the acquisition modality to the underlying theoretical concepts, we propose an application-oriented characterization, designed to help select an appropriate method based on one’s application needs and compare recent approaches. We conclude by giving hints for how to evaluate these methods and a set of research challenges to be explored.},
	language = {en},
	number = {1},
	urldate = {2024-01-16},
	journal = {Computer Graphics Forum},
	author = {Kaiser, Adrien and Ybanez Zepeda, Jose Alonso and Boubekeur, Tamy},
	month = feb,
	year = {2019},
	keywords = {3D data, computational geometry, data fitting, geometric primitives, I.3.5 Computing Methodologies/Computer Graphics: Computational Geometry and Object Modelling—Curve, shape abstraction, shape analysis, solid and object representations, surface},
	pages = {167--196},
	file = {Kaiser et al. - 2019 - A Survey of Simple Geometric Primitives Detection .pdf:C\:\\Users\\hugop\\Zotero\\storage\\YME9444A\\Kaiser et al. - 2019 - A Survey of Simple Geometric Primitives Detection .pdf:application/pdf;Snapshot:C\:\\Users\\hugop\\Zotero\\storage\\97E2ZWPG\\cgf.html:text/html},
}

@article{schnabel_efficient_2007,
	title = {Efficient {RANSAC} for {Point}‐{Cloud} {Shape} {Detection}},
	volume = {26},
	issn = {0167-7055, 1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2007.01016.x},
	doi = {10.1111/j.1467-8659.2007.01016.x},
	abstract = {In this work we present an automatic algorithm to detect basic shapes in unorganized point clouds. The algorithm decomposes the point cloud into a concise, hybrid structure of inherent shapes and a set of remaining points. Each detected shape serves as a proxy for a set of corresponding points. Our method is based on random sampling and detects planes, spheres, cylinders, cones and tori. For models with surfaces composed of these basic shapes only, e.g. CAD models, we automatically obtain a representation solely consisting of shape proxies. We demonstrate that the algorithm is robust even in the presence of many outliers and a high degree of noise. The proposed method scales well with respect to the size of the input point cloud and the number and size of the shapes within the data. Even point sets with several millions of samples are robustly decomposed within less than a minute. Moreover the algorithm is conceptually simple and easy to implement. Application areas include measurement of physical parameters, scan registration, surface compression, hybrid rendering, shape classiﬁcation, meshing, simpliﬁcation, approximation and reverse engineering.},
	language = {en},
	number = {2},
	urldate = {2024-02-06},
	journal = {Computer Graphics Forum},
	author = {Schnabel, R. and Wahl, R. and Klein, R.},
	month = jun,
	year = {2007},
	keywords = {@jenke, Surface Reconstruction},
	pages = {214--226},
	file = {Schnabel et al. - 2007 - Efficient RANSAC for Point‐Cloud Shape Detection.pdf:C\:\\Users\\hugop\\Zotero\\storage\\ZCAI22CK\\Schnabel et al. - 2007 - Efficient RANSAC for Point‐Cloud Shape Detection.pdf:application/pdf},
}

@article{chatzopoulos_mobile_2017,
	title = {Mobile {Augmented} {Reality} {Survey}: {From} {Where} {We} {Are} to {Where} {We} {Go}},
	volume = {5},
	issn = {2169-3536},
	shorttitle = {Mobile {Augmented} {Reality} {Survey}},
	url = {https://ieeexplore.ieee.org/abstract/document/7912316},
	doi = {10.1109/ACCESS.2017.2698164},
	abstract = {The boom in the capabilities and features of mobile devices, like smartphones, tablets, and wearables, combined with the ubiquitous and affordable Internet access and the advances in the areas of cooperative networking, computer vision, and mobile cloud computing transformed mobile augmented reality (MAR) from science fiction to a reality. Although mobile devices are more constrained computationalwise from traditional computers, they have a multitude of sensors that can be used to the development of more sophisticated MAR applications and can be assisted from remote servers for the execution of their intensive parts. In this paper, after introducing the reader to the basics of MAR, we present a categorization of the application fields together with some representative examples. Next, we introduce the reader to the user interface and experience in MAR applications and continue with the core system components of the MAR systems. After that, we discuss advances in tracking and registration, since their functionality is crucial to any MAR application and the network connectivity of the devices that run MAR applications together with its importance to the performance of the application. We continue with the importance of data management in MAR systems and the systems performance and sustainability, and before we conclude this survey, we present existing challenging problems.},
	urldate = {2024-02-09},
	journal = {IEEE Access},
	author = {Chatzopoulos, Dimitris and Bermejo, Carlos and Huang, Zhanpeng and Hui, Pan},
	year = {2017},
	note = {Conference Name: IEEE Access},
	keywords = {AR, Augmented reality, Cloud computing, human computer interaction, Mobile augmented reality, Mobile communication, mobile computing, Mobile computing, Sensors, Smart phones},
	pages = {6917--6950},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\hugop\\Zotero\\storage\\PWHJTFSN\\7912316.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\hugop\\Zotero\\storage\\VFXVAYL9\\Chatzopoulos et al. - 2017 - Mobile Augmented Reality Survey From Where We Are.pdf:application/pdf},
}

@misc{google_llc_codelab_raw_depth,
	title = {Google {Codelab} {\textbar} {ARCore} {Raw} {Depth}},
	url = {https://codelabs.developers.google.com/codelabs/arcore-rawdepthapi},
	abstract = {This codelab shows you steps for building an ARCore application using the new Raw Depth API.},
	language = {en},
	urldate = {2024-02-09},
	journal = {Google Codelabs},
	author = {{Google LLC} and Turner, Eric},
	month = may,
	year = {2022},
	file = {ARCore Raw Depth Part 1.html:C\:\\Users\\hugop\\Zotero\\storage\\5UGM64DA\\ARCore Raw Depth Part 1.html:text/html;ARCore Raw Depth Part 2.html:C\:\\Users\\hugop\\Zotero\\storage\\FNB27VS8\\ARCore Raw Depth Part 2.html:text/html;ARCore Raw Depth Part 3.html:C\:\\Users\\hugop\\Zotero\\storage\\M4ALWJAJ\\ARCore Raw Depth Part 3.html:text/html},
}

@misc{google_llc_arcore_doc,
	title = {{ARCore} {Developer} {Documentation}},
	url = {https://developers.google.com/ar/develop},
	abstract = {Explore an overview of Google\&\#39;s platform for building augmented reality experiences.},
	language = {en},
	urldate = {2024-02-09},
	journal = {Google for Developers},
	author = {{Google LLC}},
	file = {Depth adds realism  ARCore.html:C\:\\Users\\hugop\\Zotero\\storage\\54R9ZHDN\\Depth adds realism  ARCore.html:text/html;Overview of ARCore and supported development envir.html:C\:\\Users\\hugop\\Zotero\\storage\\QIJMQ9HN\\Overview of ARCore and supported development envir.html:text/html;Use Raw Depth in your Android app  ARCore.html:C\:\\Users\\hugop\\Zotero\\storage\\WFJ2QVFY\\Use Raw Depth in your Android app  ARCore.html:text/html},
}
